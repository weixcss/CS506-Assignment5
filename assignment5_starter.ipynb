{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.X_train = X.values\n",
    "        else:\n",
    "            self.X_train = X\n",
    "\n",
    "        if isinstance(y, pd.Series):\n",
    "            self.y_train = y.values\n",
    "        else:\n",
    "            self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        else: \n",
    "            X = X\n",
    "\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        sample_probabilities = []\n",
    "        for sample in X:\n",
    "            distances = self.compute_distance(sample, self.X_train)\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "            probability = np.sum(k_nearest_labels) / self.k\n",
    "            sample_probabilities.append(probability)\n",
    "        return np.array(sample_probabilities)\n",
    "    \n",
    "    def compute_distance(self, X1, X2):\n",
    "        X1 = np.array(X1, dtype=np.float64)\n",
    "        X2 = np.array(X2, dtype=np.float64)\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2)**2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scalar:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def check_input(self, X):\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            return X.values\n",
    "        return np.array(X)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X = self.check_input(X)\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.scale_ = np.std(X, axis=0, ddof=1)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.check_input(X)\n",
    "        return (X - self.mean_) / self.scale_\n",
    "\n",
    "    def transformv2(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "# Define data preprocessing function\n",
    "def preprocess_data(train, test):\n",
    "    train_data = pd.read_csv(train)\n",
    "    test_data = pd.read_csv(test)\n",
    "\n",
    "    train_data.drop(columns=['CustomerId', 'Surname', 'id'], inplace=True)\n",
    "    test_data.drop(columns=['CustomerId', 'Surname', 'id'], inplace=True)\n",
    "\n",
    "    train_data['HasCrCard'] = train_data['HasCrCard'].astype('object')\n",
    "    train_data['IsActiveMember'] = train_data['IsActiveMember'].astype('object')\n",
    "\n",
    "    test_data['HasCrCard'] = test_data['HasCrCard'].astype('object')\n",
    "    test_data['IsActiveMember'] = test_data['IsActiveMember'].astype('object')\n",
    "    \n",
    "    train_data = pd.get_dummies(train_data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "    test_data = pd.get_dummies(test_data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "    from scipy import stats\n",
    "\n",
    "    features = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'Exited' in features:\n",
    "        features.remove('Exited')\n",
    "    \n",
    "    def outliers(df, features, threshold=3):\n",
    "        outliers = np.zeros(df.shape[0])\n",
    "        for feature in features:\n",
    "            zScores = np.abs(stats.zscore(df[feature]))\n",
    "            outliers += (zScores > threshold).astype(int)\n",
    "        return outliers > 0\n",
    "\n",
    "    outliers = outliers(train_data, features)\n",
    "    train_data = train_data[~outliers]\n",
    "\n",
    "    scaler = scalar()\n",
    "    train_data[features] = scaler.transformv2(train_data[features])\n",
    "    test_data[features] = scaler.transform(test_data[features])\n",
    "\n",
    "    X = train_data.drop('Exited', axis=1)\n",
    "    X = X.astype('float')\n",
    "    y = train_data['Exited']\n",
    "    X_test = test_data\n",
    "\n",
    "    return X, y, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedKFold:\n",
    "    def __init__(self, n_splits=5, shuffle=True, state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.state = state\n",
    "    \n",
    "    def split(self, X, y):\n",
    "        np.random.seed(self.state)\n",
    "\n",
    "        y = np.array(y)\n",
    "        unique_classes, y_indices = np.unique(y, return_inverse=True)\n",
    "\n",
    "        n_classes = len(unique_classes)\n",
    "    \n",
    "        folds = [[] for _ in range(self.n_splits)]\n",
    "        \n",
    "        for n in range(n_classes):\n",
    "            class_indices = np.where(y_indices == n)[0]\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(class_indices)\n",
    "            fsizes = np.full(self.n_splits, len(class_indices) // self.n_splits, dtype=int)\n",
    "            fsizes[:len(class_indices) % self.n_splits] += 1\n",
    "            current = 0\n",
    "            for fold, fsize in enumerate(fsizes):\n",
    "                folds[fold].extend(class_indices[current:current + fsize])\n",
    "                current += fsize\n",
    "        \n",
    "        for fold in range(self.n_splits):\n",
    "            value_indices = np.array(folds[fold])\n",
    "            train_indices = np.array([idx for f in range(self.n_splits) if f != fold for idx in folds[f]])\n",
    "            yield train_indices, value_indices\n",
    "\n",
    "def roc_auc_score(y_true, y_scores):\n",
    "    score_indices = np.argsort(-y_scores)\n",
    "    y_true = y_true[score_indices]\n",
    "    y_scores = y_scores[score_indices]\n",
    "    indices = np.where(np.diff(y_scores))[0]\n",
    "    threshold_indices = np.r_[indices, y_true.size - 1]\n",
    "    truepos = np.cumsum(y_true)[threshold_indices]\n",
    "    falsepos = 1 + threshold_indices - truepos\n",
    "    truepos = np.r_[0, truepos]\n",
    "    falsepos = np.r_[0, falsepos]\n",
    "    falsepos = falsepos / falsepos[-1]\n",
    "    truepos = truepos / truepos[-1]\n",
    "    auc = np.trapz(truepos, falsepos)\n",
    "    return auc\n",
    "\n",
    "# Define cross-validation function\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    kfold = StratifiedKFold(n_splits = n_splits, shuffle = True, state = 43)\n",
    "    scores = []\n",
    "    for fold, (train_index, value_index) in enumerate(kfold.split(X, y), 1):\n",
    "        X_train, X_value = X.iloc[train_index].reset_index(drop=True), X.iloc[value_index].reset_index(drop=True)\n",
    "        y_train, y_value = y.iloc[train_index].reset_index(drop=True), y.iloc[value_index].reset_index(drop=True)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_probability = knn.predict(X_value)\n",
    "        score = roc_auc_score(y_value.values, y_probability)\n",
    "        scores.append(score)\n",
    "    \n",
    "    mean = np.mean(scores)\n",
    "    print(f\"ROC AUC: {mean}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9126458108796077\n",
      "Cross-validation scores: [0.9151673093846362, 0.9174517603794778, 0.9046717533211177, 0.9167977532923416, 0.9091404780204653]\n",
      "ROC AUC: 0.9000723624081737\n",
      "ROC AUC: 0.8999531647859598\n",
      "ROC AUC: 0.9126458108796077\n",
      "ROC AUC: 0.9105320277871305\n",
      "ROC AUC: 0.9163043467691783\n",
      "ROC AUC: 0.914595867124169\n",
      "ROC AUC: 0.9174686985836585\n",
      "ROC AUC: 0.9167111666476029\n",
      "ROC AUC: 0.917574210951301\n",
      "ROC AUC: 0.9177262369715871\n",
      "ROC AUC: 0.9175624311006118\n",
      "ROC AUC: 0.9176991206703274\n",
      "ROC AUC: 0.9174661509261476\n",
      "ROC AUC: 0.917643374782853\n",
      "ROC AUC: 0.9169539226344694\n",
      "ROC AUC: 0.9179266103322907\n",
      "ROC AUC: 0.9168891943369338\n",
      "ROC AUC: 0.9175222136740728\n",
      "ROC AUC: 0.9163376731141633\n",
      "ROC AUC: 0.9174410452144237\n",
      "k = 80, distance_metric = manhattan\n",
      "Best ROC AUC: 0.9179266103322907\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=20, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "k_values = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "metrics = ['euclidean', 'manhattan']\n",
    "best_k = 0\n",
    "best_metric = None\n",
    "best_score = 0\n",
    "\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "for k in k_values:\n",
    "    for metric in metrics:\n",
    "        knn = KNN(k=k, distance_metric=metric)\n",
    "        scores = cross_validate(X, y, knn)\n",
    "        mean = np.mean(scores)\n",
    "        \n",
    "        if mean > best_score:\n",
    "            best_score = mean\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "\n",
    "print(f\"k = {best_k}, distance_metric = {best_metric}\")\n",
    "print(f\"Best ROC AUC: {best_score:}\")\n",
    "\n",
    "knn = KNN(k=best_k, distance_metric=best_metric)\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predict(X_test)\n",
    "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
